

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>castle.algorithms.anm._anm &mdash; gCastle 1.0.4rc1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
    <link rel="shortcut icon" href="../../../../_static/favicon.png"/>
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=3cd93504"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            gCastle
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../castle/castle.html">castle</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">gCastle</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">castle.algorithms.anm._anm</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for castle.algorithms.anm._anm</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding=utf-8</span>
<span class="c1"># Copyright (C) 2021. Huawei Technologies Co., Ltd. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">castle.common</span> <span class="kn">import</span> <span class="n">BaseLearner</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">castle.common.independence_tests</span> <span class="kn">import</span> <span class="n">hsic_test</span>


<span class="k">class</span> <span class="nc">GPR</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimator based on Gaussian Process Regressor</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha : float or ndarray of shape (n_samples,), default=1e-10</span>
<span class="sd">        Value added to the diagonal of the kernel matrix during fitting.</span>
<span class="sd">        This can prevent a potential numerical issue during fitting, by</span>
<span class="sd">        ensuring that the calculated values form a positive definite matrix.</span>
<span class="sd">        It can also be interpreted as the variance of additional Gaussian</span>
<span class="sd">        measurement noise on the training observations. Note that this is</span>
<span class="sd">        different from using a `WhiteKernel`. If an array is passed, it must</span>
<span class="sd">        have the same number of entries as the data used for fitting and is</span>
<span class="sd">        used as datapoint-dependent noise level. Allowing to specify the</span>
<span class="sd">        noise level directly as a parameter is mainly for convenience and</span>
<span class="sd">        for consistency with Ridge.</span>

<span class="sd">    kernel : kernel instance, default=None</span>
<span class="sd">        The kernel specifying the covariance function of the GP. If None is</span>
<span class="sd">        passed, the kernel ``ConstantKernel(1.0, constant_value_bounds=&quot;fixed&quot;</span>
<span class="sd">        * RBF(1.0, length_scale_bounds=&quot;fixed&quot;)`` is used as default. Note that</span>
<span class="sd">        the kernel hyperparameters are optimized during fitting unless the</span>
<span class="sd">        bounds are marked as &quot;fixed&quot;.</span>

<span class="sd">    optimizer : &quot;fmin_l_bfgs_b&quot; or callable, default=&quot;fmin_l_bfgs_b&quot;</span>
<span class="sd">        Can either be one of the internally supported optimizers for optimizing</span>
<span class="sd">        the kernel&#39;s parameters, specified by a string, or an externally</span>
<span class="sd">        defined optimizer passed as a callable. If a callable is passed, it</span>
<span class="sd">        must have the signature::</span>

<span class="sd">            def optimizer(obj_func, initial_theta, bounds):</span>
<span class="sd">                # * &#39;obj_func&#39; is the objective function to be minimized, which</span>
<span class="sd">                #   takes the hyperparameters theta as parameter and an</span>
<span class="sd">                #   optional flag eval_gradient, which determines if the</span>
<span class="sd">                #   gradient is returned additionally to the function value</span>
<span class="sd">                # * &#39;initial_theta&#39;: the initial value for theta, which can be</span>
<span class="sd">                #   used by local optimizers</span>
<span class="sd">                # * &#39;bounds&#39;: the bounds on the values of theta</span>
<span class="sd">                ....</span>
<span class="sd">                # Returned are the best found hyperparameters theta and</span>
<span class="sd">                # the corresponding value of the target function.</span>
<span class="sd">                return theta_opt, func_min</span>

<span class="sd">        Per default, the &#39;L-BGFS-B&#39; algorithm from scipy.optimize.minimize</span>
<span class="sd">        is used. If None is passed, the kernel&#39;s parameters are kept fixed.</span>
<span class="sd">        Available internal optimizers are::</span>

<span class="sd">            &#39;fmin_l_bfgs_b&#39;</span>

<span class="sd">    n_restarts_optimizer : int, default=0</span>
<span class="sd">        The number of restarts of the optimizer for finding the kernel&#39;s</span>
<span class="sd">        parameters which maximize the log-marginal likelihood. The first run</span>
<span class="sd">        of the optimizer is performed from the kernel&#39;s initial parameters,</span>
<span class="sd">        the remaining ones (if any) from thetas sampled log-uniform randomly</span>
<span class="sd">        from the space of allowed theta-values. If greater than 0, all bounds</span>
<span class="sd">        must be finite. Note that n_restarts_optimizer == 0 implies that one</span>
<span class="sd">        run is performed.</span>

<span class="sd">    normalize_y : bool, default=False</span>
<span class="sd">        Whether the target values y are normalized, the mean and variance of</span>
<span class="sd">        the target values are set equal to 0 and 1 respectively. This is</span>
<span class="sd">        recommended for cases where zero-mean, unit-variance priors are used.</span>
<span class="sd">        Note that, in this implementation, the normalisation is reversed</span>
<span class="sd">        before the GP predictions are reported.</span>

<span class="sd">    copy_X_train : bool, default=True</span>
<span class="sd">        If True, a persistent copy of the training data is stored in the</span>
<span class="sd">        object. Otherwise, just a reference to the training data is stored,</span>
<span class="sd">        which might cause predictions to change if the data is modified</span>
<span class="sd">        externally.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation used to initialize the centers.</span>
<span class="sd">        Pass an int for reproducible results across multiple function calls.</span>
<span class="sd">        See :term: `Glossary &lt;random_state&gt;`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    from sklearn.gaussian_process import GaussianProcessRegressor</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.random.rand(10).reshape((-1, 1))</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.rand(10).reshape((-1, 1))</span>
<span class="sd">    &gt;&gt;&gt; gpr = GPR(alpha=1e-10)</span>
<span class="sd">    &gt;&gt;&gt; y_pred = gpr.estimate(x, y)</span>
<span class="sd">    &gt;&gt;&gt; print(y_pred)</span>
<span class="sd">    [[0.30898833]</span>
<span class="sd">     [0.51335394]</span>
<span class="sd">     [0.378371  ]</span>
<span class="sd">     [0.47051942]</span>
<span class="sd">     [0.51290679]</span>
<span class="sd">     [0.29678631]</span>
<span class="sd">     [0.77848816]</span>
<span class="sd">     [0.47589755]</span>
<span class="sd">     [0.21743226]</span>
<span class="sd">     [0.35258412]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Gaussian process regression model and predict x.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array</span>
<span class="sd">            Variable seen as cause</span>
<span class="sd">        y: array</span>
<span class="sd">            Variable seen as effect</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_predict: array</span>
<span class="sd">            regression predict values of x</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">y_predict</span>


<div class="viewcode-block" id="ANMNonlinear">
<a class="viewcode-back" href="../../../../castle/castle.algorithms.html#castle.algorithms.ANMNonlinear">[docs]</a>
<span class="k">class</span> <span class="nc">ANMNonlinear</span><span class="p">(</span><span class="n">BaseLearner</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Nonlinear causal discovery with additive noise models</span>

<span class="sd">    Use GPML with Gaussian kernel and independent Gaussian noise,</span>
<span class="sd">    optimizing the hyper-parameters for each regression individually.</span>
<span class="sd">    For the independence test, we implemented the HSIC with a Gaussian kernel,</span>
<span class="sd">    where we used the gamma distribution as an approximation for the</span>
<span class="sd">    distribution of the HSIC under the null hypothesis of independence</span>
<span class="sd">    in order to calculate the p-value of the test result.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Hoyer, Patrik O and Janzing, Dominik and Mooij, Joris M and Peters,</span>
<span class="sd">    Jonas and Sch√∂lkopf, Bernhard,</span>
<span class="sd">    &quot;Nonlinear causal discovery with additive noise models&quot;, NIPS 2009</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha : float, default 0.05</span>
<span class="sd">        significance level be used to compute threshold</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    causal_matrix : array like shape of (n_features, n_features)</span>
<span class="sd">        Learned causal structure matrix.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from castle.common import GraphDAG</span>
<span class="sd">    &gt;&gt;&gt; from castle.metrics import MetricsDAG</span>
<span class="sd">    &gt;&gt;&gt; from castle.datasets import DAG, IIDSimulation</span>
<span class="sd">    &gt;&gt;&gt; from castle.algorithms.anm import ANMNonlinear</span>

<span class="sd">    &gt;&gt;&gt; weighted_random_dag = DAG.erdos_renyi(n_nodes=6, n_edges=10,</span>
<span class="sd">    &gt;&gt;&gt;                                      weight_range=(0.5, 2.0), seed=1)</span>
<span class="sd">    &gt;&gt;&gt; dataset = IIDSimulation(W=weighted_random_dag, n=1000,</span>
<span class="sd">    &gt;&gt;&gt;                         method=&#39;nonlinear&#39;, sem_type=&#39;gp-add&#39;)</span>
<span class="sd">    &gt;&gt;&gt; true_dag, X = dataset.B, dataset.X</span>

<span class="sd">    &gt;&gt;&gt; anm = ANMNonlinear(alpha=0.05)</span>
<span class="sd">    &gt;&gt;&gt; anm.learn(data=X)</span>

<span class="sd">    &gt;&gt;&gt; # plot predict_dag and true_dag</span>
<span class="sd">    &gt;&gt;&gt; GraphDAG(anm.causal_matrix, true_dag, show=False, save_name=&#39;result&#39;)</span>

<span class="sd">    you can also provide more parameters to use it. like the flowing:</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.gaussian_process.kernels import Matern, RBF</span>
<span class="sd">    &gt;&gt;&gt; kernel = Matern(nu=1.5)</span>
<span class="sd">    &gt;&gt;&gt; # kernel = 1.0 * RBF(1.0)</span>
<span class="sd">    &gt;&gt;&gt; anm = ANMNonlinear(alpha=0.05)</span>
<span class="sd">    &gt;&gt;&gt; anm.learn(data=X, regressor=GPR(kernel=kernel))</span>
<span class="sd">    &gt;&gt;&gt; # plot predict_dag and true_dag</span>
<span class="sd">    &gt;&gt;&gt; GraphDAG(anm.causal_matrix, true_dag, show=False, save_name=&#39;result&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ANMNonlinear</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

<div class="viewcode-block" id="ANMNonlinear.learn">
<a class="viewcode-back" href="../../../../castle/castle.algorithms.html#castle.algorithms.ANMNonlinear.learn">[docs]</a>
    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regressor</span><span class="o">=</span><span class="n">GPR</span><span class="p">(),</span> <span class="n">test_method</span><span class="o">=</span><span class="n">hsic_test</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up and run the ANM_Nonlinear algorithm.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: numpy.ndarray or Tensor</span>
<span class="sd">            Training data.</span>
<span class="sd">        columns : Index or array-like</span>
<span class="sd">            Column labels to use for resulting tensor. Will default to</span>
<span class="sd">            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.</span>
<span class="sd">        regressor: Class</span>
<span class="sd">            Nonlinear regression estimator, if not provided, it is GPR.</span>
<span class="sd">            If user defined, must implement `estimate` method. such as :</span>
<span class="sd">                `regressor.estimate(x, y)`</span>
<span class="sd">        test_method: callable, default test_method</span>
<span class="sd">            independence test method, if not provided, it is HSIC.</span>
<span class="sd">            If user defined, must accept three arguments--x, y and keyword</span>
<span class="sd">            argument--alpha. such as :</span>
<span class="sd">                `test_method(x, y, alpha=0.05)`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span>

        <span class="c1"># create learning model and ground truth model</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

        <span class="n">node_num</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal_matrix</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)),</span>
                                    <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                                    <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">node_num</span><span class="p">),</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">flag</span> <span class="o">=</span> <span class="n">test_method</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">flag</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># test x--&gt;y</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">anm_estimate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">=</span><span class="n">regressor</span><span class="p">,</span>
                                     <span class="n">test_method</span><span class="o">=</span><span class="n">test_method</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">flag</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">causal_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="c1"># test y--&gt;x</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">anm_estimate</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">regressor</span><span class="o">=</span><span class="n">regressor</span><span class="p">,</span>
                                     <span class="n">test_method</span><span class="o">=</span><span class="n">test_method</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">flag</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">causal_matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="ANMNonlinear.anm_estimate">
<a class="viewcode-back" href="../../../../castle/castle.algorithms.html#castle.algorithms.ANMNonlinear.anm_estimate">[docs]</a>
    <span class="k">def</span> <span class="nf">anm_estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">=</span><span class="n">GPR</span><span class="p">(),</span> <span class="n">test_method</span><span class="o">=</span><span class="n">hsic_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the fitness score of the ANM model in the x-&gt;y direction.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x: array</span>
<span class="sd">            Variable seen as cause</span>
<span class="sd">        y: array</span>
<span class="sd">            Variable seen as effect</span>
<span class="sd">        regressor: Class</span>
<span class="sd">            Nonlinear regression estimator, if not provided, it is GPR.</span>
<span class="sd">            If user defined, must implement `estimate` method. such as :</span>
<span class="sd">                `regressor.estimate(x, y)`</span>
<span class="sd">        test_method: callable, default test_method</span>
<span class="sd">            independence test method, if not provided, it is HSIC.</span>
<span class="sd">            If user defined, must accept three arguments--x, y and keyword</span>
<span class="sd">            argument--alpha. such as :</span>
<span class="sd">                `test_method(x, y, alpha=0.05)`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out: int, 0 or 1</span>
<span class="sd">            If 1, residuals n is independent of x, then accept x --&gt; y</span>
<span class="sd">            If 0, residuals n is not independent of x, then reject x --&gt; y</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from castle.algorithms.anm import ANMNonlinear</span>
<span class="sd">        &gt;&gt;&gt; np.random.seed(1)</span>
<span class="sd">        &gt;&gt;&gt; x = np.random.rand(500, 2)</span>
<span class="sd">        &gt;&gt;&gt; anm = ANMNonlinear(alpha=0.05)</span>
<span class="sd">        &gt;&gt;&gt; print(anm.anm_estimate(x[:, [0]], x[:, [1]]))</span>
<span class="sd">        1</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">y_predict</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="n">test_method</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">flag</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Huawei Noah&#39;s Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>